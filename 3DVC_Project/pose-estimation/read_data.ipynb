{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import utils\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T08:03:39.075290300Z",
     "start_time": "2023-06-09T08:03:39.074292900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the following data folders\n",
    "training_data_dir = \"../datasets/training_data/data\"\n",
    "split_dir = \"../datasets/training_data/splits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_files(split_name):\n",
    "    with open(os.path.join(split_dir, f\"{split_name}.txt\"), 'r') as f:\n",
    "        prefix = [os.path.join(training_data_dir, line.strip()) for line in f if line.strip()]\n",
    "        rgb = [p + \"_color_kinect.png\" for p in prefix]\n",
    "        depth = [p + \"_depth_kinect.png\" for p in prefix]\n",
    "        label = [p + \"_label_kinect.png\" for p in prefix]\n",
    "        meta = [p + \"_meta.pkl\" for p in prefix]\n",
    "    return rgb, depth, label, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/training_data/splits\\\\val.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m rgb_files, depth_files, label_files, meta_files \u001B[38;5;241m=\u001B[39m \u001B[43mget_split_files\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mval\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mget_split_files\u001B[1;34m(split_name)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_split_files\u001B[39m(split_name):\n\u001B[1;32m----> 2\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43msplit_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m      3\u001B[0m         prefix \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(training_data_dir, line\u001B[38;5;241m.\u001B[39mstrip()) \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f \u001B[38;5;28;01mif\u001B[39;00m line\u001B[38;5;241m.\u001B[39mstrip()]\n\u001B[0;32m      4\u001B[0m         rgb \u001B[38;5;241m=\u001B[39m [p \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_color_kinect.png\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prefix]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../datasets/training_data/splits\\\\val.txt'"
     ]
    }
   ],
   "source": [
    "rgb_files, depth_files, label_files, meta_files = get_split_files('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "NUM_OBJECTS = 79\n",
    "cmap = get_cmap('rainbow', NUM_OBJECTS)\n",
    "COLOR_PALETTE = np.array([cmap(i)[:3] for i in range(NUM_OBJECTS + 3)])\n",
    "COLOR_PALETTE = np.array(COLOR_PALETTE * 255, dtype=np.uint8)\n",
    "COLOR_PALETTE[-3] = [119, 135, 150]\n",
    "COLOR_PALETTE[-2] = [176, 194, 216]\n",
    "COLOR_PALETTE[-1] = [255, 255, 225]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get familiar with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.array(Image.open(rgb_files[10])) / 255   # convert 0-255 to 0-1\n",
    "depth = np.array(Image.open(depth_files[10])) / 1000   # convert from mm to m\n",
    "label = np.array(Image.open(label_files[10]))\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(rgb)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(depth)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(COLOR_PALETTE[label])  # draw colorful segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_pickle(meta_files[10])\n",
    "meta.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['object_names'], meta['object_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_world = np.array([meta['poses_world'][idx] for idx in meta['object_ids']])\n",
    "box_sizes = np.array([meta['extents'][idx] * meta['scales'][idx] for idx in meta['object_ids']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift depth to point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic = meta['intrinsic']\n",
    "z = depth\n",
    "v, u = np.indices(z.shape)\n",
    "uv1 = np.stack([u + 0.5, v + 0.5, np.ones_like(z)], axis=-1)\n",
    "points_viewer = uv1 @ np.linalg.inv(intrinsic).T * z[..., None]  # [H, W, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "points = open3d.utility.Vector3dVector(points_viewer.reshape([-1, 3]))\n",
    "colors = open3d.utility.Vector3dVector(rgb.reshape([-1, 3]))\n",
    "pcd = open3d.geometry.PointCloud()\n",
    "pcd.points = points\n",
    "pcd.colors = colors\n",
    "open3d.visualization.draw_geometries([pcd])\n",
    "# will open another window to show the point cloud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounding boxes of poses on 2D image\n",
    "If you are curious, take a look at `utils.py`. It is very simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxed_image = np.array(rgb)\n",
    "for i in range(len(poses_world)):\n",
    "    utils.draw_projected_box3d(\n",
    "        boxed_image, poses_world[i][:3,3], box_sizes[i], poses_world[i][:3, :3], meta['extrinsic'], meta['intrinsic'],\n",
    "        thickness=2)\n",
    "\n",
    "Image.fromarray((boxed_image * 255).astype(np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data\n",
    "Testing data has everything but the poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_pickle(\"../datasets/testing_data/data/1-2-11_meta.pkl\").keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"../datasets/testing_data/data/1-2-11_color_kinect.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "707c61934e115bcff7fca79d542d7d9550159182125ff7b47ebaba93876f1688"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('captra')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
